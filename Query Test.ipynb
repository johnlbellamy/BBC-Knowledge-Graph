{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from py2neo import Graph\n",
    "\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "import en_core_web_sm\n",
    "\n",
    "from nltk import pos_tag\n",
    "from itertools import groupby\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect():\n",
    "    global graph\n",
    "    graph = Graph(\"bolt://localhost:7687\", auth = (\"neo4j\", \"test\"))\n",
    "    tx = graph.begin()\n",
    "    print('Connected...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected...\n"
     ]
    }
   ],
   "source": [
    "connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_question():\n",
    "    global question\n",
    "    question = input(\"INPUT: \")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(question):\n",
    "    \n",
    "    question_tokenized = word_tokenize(question)\n",
    "    \n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    filtered_question = [w for w in question_tokenized if not w in stop_words]\n",
    "    \n",
    "    filtered_question = []\n",
    "    \n",
    "    for w in question_tokenized:\n",
    "        \n",
    "        if w not in stop_words:\n",
    "            \n",
    "            filtered_question.append(w)\n",
    "            \n",
    "    return filtered_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Where does Louisa Lim live?\"\n",
    "filtered_question = tokenize(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Where', 'Louisa', 'Lim', 'live', '?']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "companies = [\"Lehman Brothers\",\n",
    "\"ABN Amro\",\n",
    "\"ING\",\n",
    "\"Sugar Foods\",\n",
    "\"Dresdner Kleinwort Wasserstein\",\n",
    "\"Calyon Securities\",\n",
    "\"Purvin\",\n",
    "\"Moet & Chandon\",\n",
    "\"Seton Healthcare\",\n",
    "\"EADS\",\n",
    "\"State Administration of Taxation\",\n",
    "\"Sunderland FC\",\n",
    "\"Bank of England\",\n",
    "\"AG Edwards & Sons\",\n",
    "\"SEC\",\n",
    "\"Stanley Gold\",\n",
    "\"Reliance\",\n",
    "\"Tyco International\",\n",
    "\"Santander Central Hispano\",\n",
    "\"Banco Central Hispano\",\n",
    "\"McDonald\",\n",
    "\"Nomura\",\n",
    "\"GM Europe\",\n",
    "\"Vivendi\",\n",
    "\"Barclays Capital\",\n",
    "\"Manchester United\",\n",
    "\"Barclay\",\n",
    "\"Shearman\",\n",
    "\"Bundesbank\",\n",
    "\"GM\",\n",
    "'Fiat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "companies = [c.lower() for c in companies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because we are lowering the text when we parse and clean an incoming query\n",
    "# we need to create a mapping from capitalized company names to lower-cased company nmes, since BBC\n",
    "# and thus Janus uses proper noun capitalisation for the graph. Companies are tricky,\n",
    "# because of names like ING and AG Edwards & Sons. Most people won't use the ampersand\n",
    "\n",
    "companies_map = {\"lehman brothers\":\"Lehman Brothers\",\n",
    "\"abn amro\":\"ABN Amro\",\n",
    "\"ing\":\"ING\",\n",
    "\"sugar foods\":\"Sugar Foods\",\n",
    "\"dresdner kleinwort wasserstein\":\"Dresdner Kleinwort Wasserstein\",\n",
    "\"calyon securities\":\"Calyon Securities\",\n",
    "\"purvin\":\"Purvin\",\n",
    "\"moet & chandon\":\"Moet & Chandon\",\n",
    "\"seton healthcare\":\"Seton Healthcare\",\n",
    "\"eads\":\"EADS\",\n",
    "\"state administration of taxation\":\"State Administration of Taxation\",\n",
    "\"sunderland fc\":\"Sunderland FC\",\n",
    "\"bank of england\":\"Bank of England\",\n",
    "\"ag edwards & sons\":\"AG Edwards & Sons\",\n",
    "\"sec\":\"SEC\",\n",
    "\"stanley gold\":\"Stanley Gold\",\n",
    "\"reliance\":\"Reliance\",\n",
    "\"tyco international\":\"Tyco International\",\n",
    "\"santander central hispano\":\"Santander Central Hispano\",\n",
    "\"banco central hispano\":\"Banco Central Hispano\",\n",
    "\"mcdonald\":\"McDonald\",\n",
    "\"nomura\":\"Nomura\",\n",
    "\"gm europe\":\"GM Europe\",\n",
    "\"vivendi\":\"Vivendi\",\n",
    "\"barclays capital\":\"Barclays Capital\",\n",
    "\"manchester united\":\"Manchester United\",\n",
    "\"barclay\":\"Barclay\",\n",
    "\"shearman\":\"Shearman\",\n",
    "\"bindesbank\":\"Bundesbank\",\n",
    "\"gm\":\"GM\",\n",
    "\"fiat\": \"Fiat\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "people_locations = [\"Greenspan\",\n",
    "\"Claridge\",\n",
    "\"Belo Horizonte\",\n",
    "\"Brian Taylor\",\n",
    "\"Gerhard Schroeder\",\n",
    "\"Lindemans\",\n",
    "\"Illva Saronno\",\n",
    "\"Volzhsky\",\n",
    "\"Nikolaev\",\n",
    "\"Bill\",\n",
    "\"Brad Wernle\",\n",
    "\"Nestor Kirchner\",\n",
    "\"Mangala\",\n",
    "\"Junya Tanase\",\n",
    "\"Nicolas Sarkozy\",\n",
    "\"Shanda\",\n",
    "\"Pernod Ricard\",\n",
    "\"Hall Green\",\n",
    "\"Perry Barr\",\n",
    "\"Suzuki\",\n",
    "\"Rachel Harvey\",\n",
    "\"Helen Carroll\",\n",
    "\"Isabelle Kronawitter\",\n",
    "\"David Wyss\",\n",
    "\"Manger Magazin\",\n",
    "\"Louisa Lim\",\n",
    "\"David Willey\",\n",
    "\"Sarah Rainsford\",\n",
    "\"Stefan Johannesson\",\n",
    "\"Mikoyan-Gurevich\",\n",
    "\"Emmanuel Gaillard\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "people_locations_lower = [x.lower() for x in people_locations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "people_location_map = {people_locations_lower[i]: people_locations[i] for i in range(len(people_locations))} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'emmanuel gaillard'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "people_locations_lower[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because we are lowering the text when we parse and clean an incoming query\n",
    "# we need to create a mapping from capitalized person names to lower-cased person nmes, since BBC\n",
    "# and thus Janus uses proper noun capitalisation for the graph\n",
    "people_companies = [\n",
    "\n",
    "\"Alex Potter\",\n",
    "\"Eddie Wong\",\n",
    "\"Jason Kenney\",\n",
    "\"Michael Hannigan\",\n",
    "\"Mike Powell\",\n",
    "\"Ray Neidl\",\n",
    "\"Gertz\",\n",
    "\"Louis Vuitton\",\n",
    "\"Scholl\",\n",
    "\"Philippe Camus\",\n",
    "\"Xie Xuren\",\n",
    "\"Bob Murray\",\n",
    "\"Rachel Lomax\",\n",
    "\"Gary Thayer\",\n",
    "\"Reveta Bowers\",\n",
    "\"Mukesh\",\n",
    "\"Dennis Kozlowski\",\n",
    "\"Emilio Botin\",\n",
    "\"Santander\",\n",
    "\"Bell\",\n",
    "\"Erling Refsum\",\n",
    "\"Carl-Peter Forster\",\n",
    "\"Carl Peter Forster\",\n",
    "\"Jean-Rene Fourtou\",\n",
    "\"Jean Rene Fourtou\",\n",
    "\"Orin Middleton\",\n",
    "\"Eric Cantona\",\n",
    "\"Frederick\",\n",
    "\"Emmanuel Gaillard\",\n",
    "\"Hans Reckers\",\n",
    "\"Rick Wagoner\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "people_companies_lower = [x.lower() for x in people_companies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we map upper-case to lower-case\n",
    "people_companies_map = {people_companies_lower[i]:people_companies[i] for i in range(len(people_companies))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump( companies_map, open( \"companies_map.p\", \"wb\" ) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(companies, open( \"companies.p\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(people_companies_map, open( \"people_companies.p\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(people_location_map, open( \"people_locations.p\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag(question, filtered_question):\n",
    "    \n",
    "    ner, tags = [], []\n",
    "    \n",
    "    nlp = en_core_web_sm.load()\n",
    "    \n",
    "    doc = nlp(question)\n",
    "    \n",
    "    ner = [(X.text, X.label_) for X in doc.ents]\n",
    "    \n",
    "    print(question)\n",
    "    \n",
    "    print(filtered_question)\n",
    "    \n",
    "    for token in doc:\n",
    "        \n",
    "        print((token.text, token.pos_, token.tag_, token.dep_))\n",
    "        \n",
    "    displacy.render(doc)\n",
    "    \n",
    "    tags = pos_tag(filtered_question)\n",
    "    \n",
    "    print('All tags: ',tags)\n",
    "    print('Length of the list: ',len(tags))\n",
    "    \n",
    "    groups = groupby(tags, key=lambda x: x[1])\n",
    "    \n",
    "    names_tagged = [[w for w,_ in words] for tag,words in groups if tag==\"NNP\"]\n",
    "    \n",
    "    print('Tagged names are: ',names_tagged)\n",
    "    \n",
    "    names = [\" \".join(name) for name in names_tagged if len(name)>=2]\n",
    "    \n",
    "    if len(ner) == 0:\n",
    "        \n",
    "        if any([x in companies for x in filtered_question]):\n",
    "            \n",
    "            matches = [x for x in companies if x in filtered_question]\n",
    "            \n",
    "            for m in matches:\n",
    "                \n",
    "                ner.append((m, \"ORG\"))\n",
    "            \n",
    "    return ner, tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Where', 'Louisa', 'Lim', 'live', '?']"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Where does Louisa Lim live?\n",
      "['Where', 'Louisa', 'Lim', 'live', '?']\n",
      "('Where', 'ADV', 'WRB', 'advmod')\n",
      "('does', 'AUX', 'VBZ', 'aux')\n",
      "('Louisa', 'PROPN', 'NNP', 'compound')\n",
      "('Lim', 'PROPN', 'NNP', 'nsubj')\n",
      "('live', 'VERB', 'VB', 'ROOT')\n",
      "('?', 'PUNCT', '.', 'punct')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"08fc96ebfa744e09820bdec7f324dffb-0\" class=\"displacy\" width=\"925\" height=\"399.5\" direction=\"ltr\" style=\"max-width: none; height: 399.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Where</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">does</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">Louisa</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">Lim</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">live?</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-08fc96ebfa744e09820bdec7f324dffb-0-0\" stroke-width=\"2px\" d=\"M70,264.5 C70,2.0 750.0,2.0 750.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-08fc96ebfa744e09820bdec7f324dffb-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,266.5 L62,254.5 78,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-08fc96ebfa744e09820bdec7f324dffb-0-1\" stroke-width=\"2px\" d=\"M245,264.5 C245,89.5 745.0,89.5 745.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-08fc96ebfa744e09820bdec7f324dffb-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,266.5 L237,254.5 253,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-08fc96ebfa744e09820bdec7f324dffb-0-2\" stroke-width=\"2px\" d=\"M420,264.5 C420,177.0 565.0,177.0 565.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-08fc96ebfa744e09820bdec7f324dffb-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M420,266.5 L412,254.5 428,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-08fc96ebfa744e09820bdec7f324dffb-0-3\" stroke-width=\"2px\" d=\"M595,264.5 C595,177.0 740.0,177.0 740.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-08fc96ebfa744e09820bdec7f324dffb-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M595,266.5 L587,254.5 603,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tags:  [('Where', 'WRB'), ('Louisa', 'NNP'), ('Lim', 'NNP'), ('live', 'NN'), ('?', '.')]\n",
      "Length of the list:  5\n",
      "Tagged names are:  [['Louisa', 'Lim']]\n"
     ]
    }
   ],
   "source": [
    "ner,tags = tag(question, filtered_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Where', 'WRB'),\n",
       " ('Louisa', 'NNP'),\n",
       " ('Lim', 'NNP'),\n",
       " ('live', 'NN'),\n",
       " ('?', '.')]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RESTAURANTS NEAR DALLAS <- \n",
    "##### <- code that kinda work \n",
    "##### <- towards \n",
    "### Code that makes query work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def params_builder(ner):\n",
    "    \n",
    "    params, params_2 = {}, {}\n",
    "    \n",
    "    if len(ner) == 1:\n",
    "        \n",
    "        if (ner[0][1] == 'GPE') or (ner[0][1] == 'LOC'):\n",
    "            \n",
    "            if (ner[0][0] == \"US\") or (ner[0][0] == \"USA\"):\n",
    "                \n",
    "                country_ = 'United States'\n",
    "                \n",
    "            elif (ner[0][0] == \"UK\"):\n",
    "                \n",
    "                country_ = 'United Kingdom'\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                country = ner[0][0]\n",
    "                \n",
    "                params = {}\n",
    "                \n",
    "                params[\"country\"] = country\n",
    "                \n",
    "                print(params)\n",
    "                \n",
    "        elif (ner[0][1] == 'ORG'):\n",
    "            \n",
    "            org = ner[0][0]\n",
    "            \n",
    "            params = {}\n",
    "            \n",
    "            try:\n",
    "                params[\"org\"] = companies_map[org] # get our mapped version to make sure we get the capitalized proper noun\n",
    "                \n",
    "            except:\n",
    "                \n",
    "                if org[0].islower():\n",
    "                    params[\"org\"] = org[0].toupper()+org[1:]\n",
    "            \n",
    "            print(params)\n",
    "            \n",
    "        elif (ner[0][1] == 'PERSON'):\n",
    "            \n",
    "            person = ner[0][0]\n",
    "            \n",
    "            params = {}\n",
    "            \n",
    "            params[\"person\"] = person\n",
    "            \n",
    "            print(params)\n",
    "            \n",
    "    elif len(ner) > 1:\n",
    "        \n",
    "        name1 = ner[0][0]\n",
    "        \n",
    "        name2 = ner[1][0]\n",
    "        \n",
    "        params_2 = {\"name1\":name1, \"name2\":name2} # looking for first and last name\n",
    "        print(params_2)\n",
    "        \n",
    "    return params, params_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "params, params_2 =  params_builder(ner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finally, we pick the right query based on verbs.\n",
    "# the query + params will be sent to Neo4j\n",
    "def query_picker(tags, params):\n",
    "    \n",
    "    label_p = \"(p:Person)\"\n",
    "    label_o = \"(o:Company)\"\n",
    "    label_l = \"(l:NE_Location)\"\n",
    "    works = \"-[r:WORKS_FOR]-\"\n",
    "    lives = \"-[:LIVES_IN]-\"\n",
    "\n",
    "    query1 = '''\n",
    "    match {} {} {}\n",
    "    where p.value IN $person\n",
    "    return p.value as Name,r.value as Works_as,o.value as at\n",
    "    '''.format(label_p,works,label_o)\n",
    "\n",
    "    query1_1 = '''\n",
    "    match {} {} {}\n",
    "    where o.value IN $org\n",
    "    return o.value as Organization, collect(distinct p.value) as Person, r.value as Position\n",
    "    '''.format(label_p,works,label_o)\n",
    "\n",
    "    query2 = '''\n",
    "    match (p:Person {value:$person})-[r:LIVES_IN]-(l:Location)\n",
    "    return p.value as Person, l.value as STAYS_AT\n",
    "    '''\n",
    "\n",
    "    query3 = '''\n",
    "    MATCH (p1:NER_Person:Tag{ value: $name1 }),(p2:NER_Person:Tag{ value: $name2 }), p = shortestPath((p1)-[*..15]-(p2))\n",
    "    RETURN p1.value as Person1, p2.value as Person2, p as Relation\n",
    "    '''\n",
    "\n",
    "    query4 = '''\n",
    "    MATCH (p:NER_Person)-[w:LIVES_IN]->(o:NER_Location)\n",
    "    RETURN p.value as Person ,o.value as Lives_in\n",
    "    '''.format(label_p,lives,label_o)\n",
    "\n",
    "    query5 = '''\n",
    "    MATCH (p:NER_Person)-[:LIVES_IN]->(l:NER_Location), (p)-[w:WORKS_AT]-(o:NER_Organization)\n",
    "    RETURN p.value as Person, l.value as Lives_in, o.value as Works_at, w.AS as Position\n",
    "    '''\n",
    "\n",
    "    query6 = '''\n",
    "    MATCH (s:Sentence)-[st:SENTENCE_TAG_OCCURRENCE]->(n:TagOccurrence), (s)-[h:HAS_TAG]-(p:NER_Person), (s)-[h]-(o:NER_Organization)\n",
    "    where n.value IN [\"said\",\"says\",\"think\",\"thinks\"] AND (p.value in $names OR o.value in $org)\n",
    "    return s.text as Sentence, p.value as Person\n",
    "    '''\n",
    "    \n",
    "    query7 = '''\n",
    "    match (a:Article)-[:HAS_ANNOTATED_TEXT]-(at:AnnotatedText)-[:CONTAINS_SENTENCE]-(s:Sentence)-[:SENTENCE_TAG_OCCURRENCE]-(t:TagOccurrence)-[:TAG_OCCURRENCE_TAG]-(o:NER_Organization)\n",
    "    where o.value = $org\n",
    "    return distinct a.Text\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    query8 = '''\n",
    "    match (a:Article)-[:HAS_ANNOTATED_TEXT]-(at:AnnotatedText)-[:CONTAINS_SENTENCE]-(s:Sentence)-[:SENTENCE_TAG_OCCURRENCE]-(t:TagOccurrence)-[:TAG_OCCURRENCE_TAG]-(p:NER_Person)\n",
    "    where p.value = $person\n",
    "    return a.Text\n",
    "    \n",
    "    '''\n",
    "        \n",
    "    for word,tag in tags:\n",
    "        \n",
    "        if word in ['work','do']:\n",
    "            verb = word\n",
    "            query = query1\n",
    "            print('(q1) We have a verb: ',verb)\n",
    "            print(query)\n",
    "            print(graph.run(query,params).data())\n",
    "        elif word in ['works','at']:\n",
    "            verb = word\n",
    "            print('(q1_1) We have an org: ',word)\n",
    "            print(graph.run(query1_1,params).to_table())\n",
    "        elif word in ['live','reside','stay']:\n",
    "            verb = word\n",
    "            print('(q2) We have a verb: ',verb)\n",
    "            return graph.run(query2,params).data()\n",
    "        elif word in ['related','relation']:\n",
    "            verb = word\n",
    "            print('(q3) We have a verb: ',verb)\n",
    "            print(graph.run(query3,params_2).data())\n",
    "        elif word in ['live','lives']:\n",
    "            verb = word\n",
    "            print('(q4) We have a verb: ',verb)\n",
    "            return graph.run(query4).to_table()\n",
    "        elif word in ['everyone']:\n",
    "            verb = word\n",
    "            print('(q5) We have a verb (s): ',verb)\n",
    "            print(graph.run(query5).to_table()) \n",
    "        elif word in ['think', 'says', 'say']:\n",
    "            verb = word\n",
    "            print('(q6) We have a verb: ',verb)\n",
    "            print(graph.run(query6,params).to_table()) \n",
    "            \n",
    "        elif word in ['article','articles']:\n",
    "            \n",
    "            if params.get('org'):\n",
    "                \n",
    "                print('(q7) We have an article: ',word)\n",
    "                return graph.run(query7,params).data() \n",
    "            \n",
    "            \n",
    "            else:\n",
    "                words = [x[0] for x in tags if x[1] == \"NNP\"] \n",
    "                print('(q8) We have an article: ',word)    \n",
    "                params = {\"person\":\" \".join(words)}\n",
    "                return graph.run(query8, params).data()\n",
    "                \n",
    "           \n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Where', 'WRB'),\n",
       " ('Louisa', 'NNP'),\n",
       " ('Lim', 'NNP'),\n",
       " ('live', 'NN'),\n",
       " ('?', '.')]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# connect -> tokenize -> tag -> params_builder -> query_picker\n",
    "tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(q2) We have a verb:  live\n"
     ]
    }
   ],
   "source": [
    "results = query_picker(tags, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'person': 'Louisa Lim'}"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#params\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Person': 'Louisa Lim', 'STAYS_AT': 'Beijing'}]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# response from Neo4j\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('articles', 'NNS'), ('Lisa', 'NNP'), ('Lim', 'NNP')]"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
